{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10728465,"sourceType":"datasetVersion","datasetId":6651243}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency, pointbiserialr\nfrom scipy.stats import chi2_contingency, f_oneway","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load your dataset\ndf = pd.read_csv('/kaggle/input/onlytimestamp/fulltimestamponly.csv',parse_dates=True,on_bad_lines='skip')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = ['year', 'month', 'date']\ncat_cols = ['Title', 'Author','publisher']\nless_cat_cols = ['day','Group', 'Format','genre',]\ntarget_col = 'rank'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert timestamp to datetime\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\n\n# Sorting by timestamp for better trend visualization\ndf = df.sort_values(by='timestamp')\n\n# Plot Rank Trend Over Time\nplt.figure(figsize=(12, 5))\nsns.lineplot(x='timestamp', y='rank', data=df, marker='o')\nplt.gca().invert_yaxis()  # Lower rank is better, so invert the axis\nplt.xlabel('Timestamp')\nplt.ylabel('Rank')\nplt.title('Book Rank Trend Over Time')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import chi2_contingency\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef check_correlation_categorical(df, target_column, cat_columns):\n    results = {}\n\n    for cat_column in cat_columns:\n        contingency_table = pd.crosstab(df[cat_column], df[target_column])\n        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n\n        results[cat_column] = {\n            \"status\": \"Columns correlated\" if p_value <= 0.05 else \"Columns not correlated\",\n            \"chi2_statistic\": round(chi2, 3),\n            \"p_value\": round(p_value, 5),\n            \"dof\": dof\n        }\n\n    return results\n\n# Call the function for `cat_cols`\nchi_square_results = check_correlation_categorical(df, target_col, cat_cols)\nprint(chi_square_results)\n\n# Print Chi-Square results in a structured format for cat_cols\nprint(\"\\nChi-Square Test Results for cat_cols (Categorical vs Numerical):\\n\")\nfor col, values in chi_square_results.items():\n    print(f\"Column: {col}\")\n    print(f\"  Status         : {values['status']}\")\n    print(f\"  Chi2-Statistic : {values['chi2_statistic']}\")\n    print(f\"  P-Value        : {values['p_value']}\")\n    print(f\"  Degrees of Freedom : {values['dof']}\")\n    print(\"-\" * 40)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import pearsonr\n\n# Encoding categorical variables\nencoder = LabelEncoder()\ndf1_encoded = df1.copy()\ndf1_encoded[\"Author\"] = encoder.fit_transform(df1[\"Author\"])\ndf1_encoded[\"Title\"] = encoder.fit_transform(df1[\"Title\"])\ndf1_encoded[\"publisher\"] = encoder.fit_transform(df1[\"publisher\"])\n\n# Calculating correlation\ncorrelation_matrix = df1_encoded.corr()\n\n# Checking correlation with p-values and printing status\nprint(\"Correlation Analysis with Rank:\\n\")\nfor col in [\"Author\", \"Title\", \"publisher\"]:\n    corr, pval = pearsonr(df1_encoded[\"rank\"], df1_encoded[col])\n    \n    # Determine significance\n    if pval < 0.05:\n        status = \"Correlation\"\n    else:\n        status = \"No Correlation\"\n    \n    print(f\"{col}: Correlation = {corr:.4f}, p-value = {pval:.4f} → {status}\")\n\n\n\n# Interpretation Guide:\n# - If p-value < 0.05 → Statistically significant correlation\n# - If p-value >= 0.05 → No significant correlation","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_anova(df, target_column, cat_columns):\n    results = {}\n\n    for cat_column in cat_columns:\n        grp_data = df.groupby(cat_column)[target_column].apply(list)\n\n        if len(grp_data) > 1:  # Ensure at least two groups for ANOVA\n            f_statistic, p_value = f_oneway(*grp_data)\n\n            results[cat_column] = {\n                \"status\": \"Columns correlated\" if p_value <= 0.05 else \"Columns not correlated\",\n                \"f_statistic\": round(f_statistic, 3),\n                \"p_value\": round(p_value, 5)\n            }\n\n    return results\n\n# Call the function for `less_cat_cols`\nanova_results = check_anova(df, target_col, less_cat_cols)\nprint(anova_results)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}